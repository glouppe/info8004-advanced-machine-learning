{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student presentations\n",
    "\n",
    "Instructions:\n",
    "- You are tasked to deliver a 20-minute lecture on the paper and its necessary background, followed by a 10-minute Q&A session.\n",
    "- Your slides will have to be submitted on Gradescope the day before your presentation.\n",
    "- Presentations are public. You are all requested to attend all presentations and support your peers.\n",
    "- This assignment will count for 40% of the final grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = \"\"\"Kaplan et al, \"Scaling Laws for Neural Language Models\", 2022.\n",
    "Ouyang et al, \"Training language models to follow instructions with human feedback\", 2022.\n",
    "Schuhmann et al, \"LAION-5B: An open large-scale dataset for training next generation image-text models\", 2022.\n",
    "Grinsztajn et al., \"Why do tree-based models still outperform deep learning on typical tabular data?\", 2022\n",
    "Mikolov et al, \"Distributed Representations of Words and Phrases and their Compositionality\", 2013.\n",
    "Groeneveld et al, \"OLMo: Accelerating the Science of Language Models\", 2024.\n",
    "Lam et al, \"Learning skillful medium-range global weather forecasting\", 2023.\n",
    "Schaeffer et al, \"Are Emergent Abilities of Large Language Models a Mirage?\", 2023.\n",
    "Angelopoulos et al, \"Prediction-powered inference\", 2023.\n",
    "Garrido et al, \"On the duality between contrastive and non-contrastive self-supervised learning\", 2023.\n",
    "Gemini Team, \"Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context\", 2024.\n",
    "Merchant et al, \"Scaling deep learning for materials discovery\", 2023.\n",
    "Bardes et al, \"Revisiting Feature Prediction for Learning Visual Representations from Video\", 2024.\n",
    "Kirillov et al, \"Segment anything\", 2023.\n",
    "Nguyen et al, \"Sequence modeling and design from molecular to genome scale with Evo\", 2024.\n",
    "Brohan et al, \"RT-2: Vision-Language-Action Models\", 2023.\n",
    "Song et al, \"Consistency models\", 2023.\n",
    "Lipman et al, \"Flow Matching for Generative Modeling\", 2022.\"\"\"\n",
    "papers = papers.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = \"\"\"DAOUD Samuel\n",
    "CLANCY Turlagh, VERHULST Louis\n",
    "GENITO Giuseppe, LEONE Rosaria\n",
    "GERARD Manon, ROBYNS Dorian\n",
    "IAMURRI Pierre\n",
    "LABIB Yassir, VINDERS Adrien\n",
    "DELABRASSINEBONARDEAUX Maxence, PIERRE Jérome\n",
    "MPARIRWA Julien\n",
    "LU Benoit, PALMQVIST Axel\n",
    "GIOURGAS Nicolas, RUTH Matteo\n",
    "DIGIROLAMO Lukas, HANSEN Julien\"\"\"\n",
    "groups = groups.split(\"\\n\")\n",
    "sum([len(g.split(\",\")) for g in groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Mikolov et al, \"Distributed Representations of Words and Phrases and their Compositionality\", 2013.\n",
      "--> DAOUD Samuel\n",
      "\n",
      "- Merchant et al, \"Scaling deep learning for materials discovery\", 2023.\n",
      "--> CLANCY Turlagh, VERHULST Louis\n",
      "\n",
      "- Nguyen et al, \"Sequence modeling and design from molecular to genome scale with Evo\", 2024.\n",
      "--> GENITO Giuseppe, LEONE Rosaria\n",
      "\n",
      "- Angelopoulos et al, \"Prediction-powered inference\", 2023.\n",
      "--> GERARD Manon, ROBYNS Dorian\n",
      "\n",
      "- Groeneveld et al, \"OLMo: Accelerating the Science of Language Models\", 2024.\n",
      "--> IAMURRI Pierre\n",
      "\n",
      "- Schaeffer et al, \"Are Emergent Abilities of Large Language Models a Mirage?\", 2023.\n",
      "--> LABIB Yassir, VINDERS Adrien\n",
      "\n",
      "- Kaplan et al, \"Scaling Laws for Neural Language Models\", 2022.\n",
      "--> DELABRASSINEBONARDEAUX Maxence, PIERRE Jérome\n",
      "\n",
      "- Brohan et al, \"RT-2: Vision-Language-Action Models\", 2023.\n",
      "--> MPARIRWA Julien\n",
      "\n",
      "- Lipman et al, \"Flow Matching for Generative Modeling\", 2022.\n",
      "--> LU Benoit, PALMQVIST Axel\n",
      "\n",
      "- Garrido et al, \"On the duality between contrastive and non-contrastive self-supervised learning\", 2023.\n",
      "--> GIOURGAS Nicolas, RUTH Matteo\n",
      "\n",
      "- Gemini Team, \"Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context\", 2024.\n",
      "--> DIGIROLAMO Lukas, HANSEN Julien\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "permutation = np.random.permutation(len(papers))\n",
    "for g, t in zip(groups, permutation):\n",
    "    print(\"-\", papers[t])\n",
    "    print(\"-->\", g) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Grinsztajn et al., \"Why do tree-based models still outperform deep learning on typical tabular data?\", 2022\n",
      "- Ouyang et al, \"Training language models to follow instructions with human feedback\", 2022.\n",
      "- Lam et al, \"Learning skillful medium-range global weather forecasting\", 2023.\n",
      "- Song et al, \"Consistency models\", 2023.\n",
      "- Bardes et al, \"Revisiting Feature Prediction for Learning Visual Representations from Video\", 2024.\n",
      "- Schuhmann et al, \"LAION-5B: An open large-scale dataset for training next generation image-text models\", 2022.\n",
      "- Kirillov et al, \"Segment anything\", 2023.\n"
     ]
    }
   ],
   "source": [
    "# Unassigned papers\n",
    "for t in permutation[len(groups):]:\n",
    "    print(\"-\", papers[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swaps\n",
    "\n",
    "You are allowed to change your paper for any of the unassigned papers above. Remaining papers will be assigned on a first-come-first-served basis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
